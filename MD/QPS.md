一个系统吞吐量的计算方法(并发数,QPS,响应时间等指标)


以我现在身处的项目为例,计算系统中常用的指标数据:

在开发的项目为"车位预定"业务,顾名思义,用户可以在抵达目的地之前,可以通过APP对目的地的停车场进行车位预定.

在计算指标数据之前,需要对业务分几个维度的分析:

1.用户使用时间段 :有需要使用预约车位的用户,可以定义为商务人员在拜访客户之前,先查询目的地的车位空余情况.预计在早上9点-10点之间;14点-15点之间.

2.用户完成操作时长 :app的体验,可以使用户在从登陆到完成预定业务,大致使用时间为4分钟.

3.预计使用人数 :初期推广粒度,预计服务深圳用户为3-4万人.

折算系统吞吐量参数:

1.QPS底限:每秒请求数=30000/60*60s => 8.3request/s ;QPS上限 => 11.1request/s

2.平均响应时间(ART):4*60s => 240s

3.并发数:系统同时处理请求数(事务性处理)=QPS*ART => 1992个 至 2664个

一个系统的吞吐能力与业务压力,呈反比(当业务压力增大时,系统吞吐能力会下降).因为系统的消耗,包括磁盘IO,内存占用,CPU的负荷.

已经搜集到的全国停车场数据存量约18w条,每周新增更改数为2000条以内,因为业务上,不仅提供车位预定,还提供车场信息查询业务,
所以,从业务形态上来看对停车场查询的业务 >> 车位预定的业务.

即:查询操作 >> 插入操作

本身DB为了数据安全采用的主从同步结构 & 应用服务器 可以采用读写分离的方案.
MySQL支持主从同步，实时将主库的数据增量复制到从库，而且一个主库可以连接多个从库同步。
利用此特性,我们在应用服务端对每次请求做读写判断,若是写请求,则把这次请求内的所有DB操作发向主库;若是读请求,则把这次请求内的所有DB操作发向从库.

见请求.png

实现了读写分离之后,减轻了主库的写操作,读压力转移到了从库之中.主库压力减小了5-8倍的样子.

从库(读)可以水平扩展硬件,当读取停车场数据的请求增大时,可直接给从库添加设备,从硬件上缓解读的压力.

紧接着,如何监控主从同步状态成为了运维的关键

在从库机器上,执行show slave status,查看Seconds_Behind_Master值,代表主从同步从库落后主库的时间,单位为秒,若同步无延迟,这个值为0.

MySQL主从延迟一个重要的原因之一是主从复制是单线程执行.

优化方案如下:

1.优化MySQL参数,比如增大innodb_buffer_pool_size,让更多操作在MySQL内存中完成,减少磁盘操作.

2.业务SQL的优化,查找出执行计划中时间最长的SQL语句,从本质上提高.

3.通过执行计划,查看SQL的全表扫描操作的频次;查看在使用索引的过程中,击中索引的几率.

4.降低高水位(Oracle中),对索引进行优化等.

随着业务的增加,用户数据量不断扩大,原来大而全的表结构,显得十分臃肿,并且在master中发现,insert,update,等操作会出现延迟现象.

此时由于master不能使用扩容来提高性能,进而,在架构上需要对业务和表结构进行分库分表.

将每个业务独立出来,形成独立的master-slave架构,避免或减少跨库操作.

***重点***
在SQL语句的使用上,避免使用join操作;分库分表后,对SQL进行组装,先查出一张表的id,然后用此id到相关表中查询.

原则上是将复杂的SQL简单化,粗粒度的形成查询关联操作.

========================================================================
预测未来可能会涉及到架构上的技术点:

曾经看过一篇美团的主键ID生成策略的内容,赶脚会在未来数据量增加的时候,和对数据做切片的时候 使用到.

DB层 与 WEB层之间可以增加一次数据访问层:系统级别包括缓存,MQ和ID生成器

1.其中对缓存的更新,可以使用与MQ的整合,用异步的方式通过MQ对redis进行更新.

2.MQ的消息处理的粒度,可以分为粗粒度的MessageListen监听级别   和   细粒度的事务管理级别,也可以更进一步与DB层嵌套事务管理.

3.对ID生成器的处理可用于业务拆分的核心基础.eg:以对订单拆分为例

优点是数据分布均匀,不会出现一个数据库数据极大或极小的情况;缺点是数据太分散,不利于做聚合查询.

ID生成器是整个水平分库的核心,它决定了如何拆分数据,以及查询存储-检索数据.ID需要跨库全局唯一,否则会引发业务层的冲突.此外,ID必须是数字且升序,这主要是考虑到升序的ID能保证MySQL的性能.同时,ID生成器必须非常稳定,因为任何故障都会影响所有的数据库操作.

Instagram的ID生成算法.方案如下:

1.整个ID的二进制长度为64位

2.前36位使用时间戳,以保证ID是升序增加(从某个时间节点2017-01-01开始的秒数)

3.中间13位是分库标识,用来标识当前这个ID对应的记录在哪个数据库中

4.后15位为自增序列,以保证在同一秒内并发时,ID不会重复.每个shard库都有一个自增序列表,生成自增序列时,从自增序列表中获取当前自增序列值,并加1,做为当前ID的后15位

之所以,把问题考虑到之前,是因为技术的积累和知识的沉淀,待需要之时,可以给出建设性的意见和建议.架构上内容,还在不断的学习,希望越来越6!












